{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Week 3: Multi-View Structure from Motion with Bundle Adjustment\n",
        "CS436 Computer Vision - 3D Scene Reconstruction Project\n",
        "\n",
        "Implements:\n",
        "- Incremental PnP registration\n",
        "- Map expansion with proper correspondence tracking\n",
        "- Bundle adjustment for global refinement\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import open3d as o3d\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import least_squares\n",
        "from scipy import stats\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONFIGURATION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# For Google Colab - adjust path as needed\n",
        "IMAGE_FOLDER = \"/content/frames/ImagesForComputerVision\"\n",
        "MAX_DIM = 640  # Resize to manage memory\n",
        "MIN_MATCHES_PNP = 8  # Minimum matches for PnP\n",
        "MIN_MATCHES_TRIANGULATION = 15  # Minimum matches to triangulate new points\n",
        "REPROJECTION_THRESHOLD = 8.0  # RANSAC threshold (pixels)\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 1: LOAD AND RESIZE IMAGES\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: LOAD AND RESIZE IMAGES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 1: LOADING IMAGES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "image_paths = sorted(glob(os.path.join(IMAGE_FOLDER, \"*.*\")))\n",
        "images = []\n",
        "for path in tqdm(image_paths, desc=\"Loading images\"):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        continue\n",
        "    h, w = img.shape[:2]\n",
        "    scale = MAX_DIM / max(h, w)\n",
        "    new_size = (int(w*scale), int(h*scale))\n",
        "    resized = cv2.resize(img, new_size)\n",
        "    images.append(resized)\n",
        "\n",
        "print(f\"âœ… Loaded {len(images)} images. Size: {images[0].shape[:2]}\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 2: CAMERA INTRINSICS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2: CAMERA INTRINSICS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 2: CAMERA INTRINSICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "h, w = images[0].shape[:2]\n",
        "\n",
        "def get_camera_matrix(image_path, sensor_width_mm=9.8, default_fl_mm=6.9):\n",
        "    \"\"\"Extract focal length from EXIF or use default\"\"\"\n",
        "    try:\n",
        "        import piexif\n",
        "        exif = piexif.load(image_path)\n",
        "        fl = exif['Exif'][piexif.ExifIFD.FocalLength]\n",
        "        fl_mm = fl[0] / fl[1]\n",
        "        print(f\"ðŸ“· EXIF focal length: {fl_mm:.2f} mm\")\n",
        "    except Exception:\n",
        "        fl_mm = default_fl_mm\n",
        "        print(f\"ðŸ“· Using default focal length: {fl_mm:.2f} mm\")\n",
        "    \n",
        "    fx = (fl_mm / sensor_width_mm) * w\n",
        "    K = np.array([\n",
        "        [fx, 0, w/2],\n",
        "        [0, fx, h/2],\n",
        "        [0, 0, 1]\n",
        "    ], dtype=float)\n",
        "    return K\n",
        "\n",
        "K = get_camera_matrix(image_paths[0])\n",
        "print(f\"Camera matrix K:\\n{K}\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 3: FEATURE EXTRACTION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: FEATURE EXTRACTION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 3: SIFT FEATURE EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "sift = cv2.SIFT_create(nfeatures=2000)\n",
        "keypoints_list = []\n",
        "descriptors_list = []\n",
        "\n",
        "for img in tqdm(images, desc=\"Extracting SIFT\"):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kp, des = sift.detectAndCompute(gray, None)\n",
        "    keypoints_list.append(kp)\n",
        "    descriptors_list.append(des)\n",
        "\n",
        "print(f\"âœ… Extracted features for {len(images)} images\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 4: FEATURE MATCHING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 4: FEATURE MATCHING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 4: FEATURE MATCHING (FLANN)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "flann = cv2.FlannBasedMatcher(\n",
        "    dict(algorithm=FLANN_INDEX_KDTREE, trees=5),\n",
        "    dict(checks=50)\n",
        ")\n",
        "\n",
        "def match_features(idx1, idx2, ratio_thresh=0.75):\n",
        "    \"\"\"Match features between two images using Lowe's ratio test\"\"\"\n",
        "    des1, des2 = descriptors_list[idx1], descriptors_list[idx2]\n",
        "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
        "        return []\n",
        "    \n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "    good = []\n",
        "    for pair in matches:\n",
        "        if len(pair) == 2:\n",
        "            m, n = pair\n",
        "            if m.distance < ratio_thresh * n.distance:\n",
        "                good.append(m)\n",
        "    return good\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 5: TWO-VIEW INITIALIZATION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 5: TWO-VIEW INITIALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 5: TWO-VIEW INITIALIZATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find good initial pair\n",
        "i0, i1 = 0, 1\n",
        "matches_01 = match_features(i0, i1)\n",
        "print(f\"Initial pair: images {i0} and {i1} with {len(matches_01)} matches\")\n",
        "\n",
        "# Extract point correspondences\n",
        "pts1 = np.float32([keypoints_list[i0][m.queryIdx].pt for m in matches_01])\n",
        "pts2 = np.float32([keypoints_list[i1][m.trainIdx].pt for m in matches_01])\n",
        "\n",
        "# Estimate Essential Matrix and recover pose\n",
        "E, mask_E = cv2.findEssentialMat(pts1, pts2, K, method=cv2.RANSAC, \n",
        "                                  prob=0.999, threshold=1.0)\n",
        "_, R01, t01, mask_pose = cv2.recoverPose(E, pts1, pts2, K, mask=mask_E)\n",
        "\n",
        "print(f\"âœ… Recovered initial pose with {mask_pose.sum()} inliers\")\n",
        "\n",
        "# Triangulate initial points\n",
        "inliers = mask_pose.ravel().astype(bool)\n",
        "pts1_inl = pts1[inliers]\n",
        "pts2_inl = pts2[inliers]\n",
        "\n",
        "P0 = K @ np.hstack((np.eye(3), np.zeros((3,1))))\n",
        "P1 = K @ np.hstack((R01, t01))\n",
        "\n",
        "X4 = cv2.triangulatePoints(P0, P1, pts1_inl.T, pts2_inl.T)\n",
        "points_3d_hom = (X4[:3] / X4[3]).T\n",
        "\n",
        "# Cheirality check - keep only points in front of both cameras\n",
        "def check_positive_depth(P, points_3d):\n",
        "    \"\"\"Check if 3D points have positive depth\"\"\"\n",
        "    points_h = np.hstack([points_3d, np.ones((points_3d.shape[0], 1))])\n",
        "    points_cam = (P @ points_h.T).T\n",
        "    return points_cam[:, 2] > 0\n",
        "\n",
        "mask_cam0 = check_positive_depth(P0, points_3d_hom)\n",
        "mask_cam1 = check_positive_depth(P1, points_3d_hom)\n",
        "valid_mask = mask_cam0 & mask_cam1\n",
        "\n",
        "points_3d = points_3d_hom[valid_mask]\n",
        "pts1_valid = pts1_inl[valid_mask]\n",
        "pts2_valid = pts2_inl[valid_mask]\n",
        "\n",
        "print(f\"âœ… Initial reconstruction: {points_3d.shape[0]} 3D points\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 6: DATA STRUCTURES FOR INCREMENTAL SfM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 6: DATA STRUCTURES FOR INCREMENTAL SfM\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 6: INITIALIZING SfM DATA STRUCTURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Store camera poses: camera_poses[img_idx] = (R, t)\n",
        "camera_poses = {\n",
        "    i0: (np.eye(3), np.zeros((3,1))),\n",
        "    i1: (R01, t01)\n",
        "}\n",
        "\n",
        "# Store 3D points as a list (will grow dynamically)\n",
        "point_cloud = [p for p in points_3d]\n",
        "\n",
        "# Map: point_idx -> {img_idx: feature_idx}\n",
        "# This tracks which 2D features correspond to each 3D point\n",
        "point_observations = {}\n",
        "\n",
        "# Build initial observations\n",
        "matches_01_inliers = [matches_01[i] for i, valid in enumerate(inliers) if valid]\n",
        "matches_01_valid = [matches_01_inliers[i] for i, valid in enumerate(valid_mask) if valid]\n",
        "\n",
        "for pt_idx, match in enumerate(matches_01_valid):\n",
        "    point_observations[pt_idx] = {\n",
        "        i0: match.queryIdx,\n",
        "        i1: match.trainIdx\n",
        "    }\n",
        "\n",
        "registered = {i0, i1}\n",
        "print(f\"âœ… Initialized: {len(point_cloud)} points, {len(registered)} cameras\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 7: INCREMENTAL PnP REGISTRATION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 7: INCREMENTAL PnP REGISTRATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 7: INCREMENTAL PNP REGISTRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def find_2d3d_correspondences(new_img_idx, registered_imgs):\n",
        "    \"\"\"\n",
        "    Find 2D-3D correspondences for a new image.\n",
        "    Returns: (points_3d, points_2d, point_indices)\n",
        "    \"\"\"\n",
        "    pts_3d = []\n",
        "    pts_2d = []\n",
        "    pt_indices = []\n",
        "    \n",
        "    # Try matching with each registered image\n",
        "    for reg_idx in registered_imgs:\n",
        "        matches = match_features(reg_idx, new_img_idx)\n",
        "        \n",
        "        for m in matches:\n",
        "            feat_idx_reg = m.queryIdx\n",
        "            feat_idx_new = m.trainIdx\n",
        "            \n",
        "            # Check if this feature in registered image corresponds to a 3D point\n",
        "            for pt_idx, obs in point_observations.items():\n",
        "                if reg_idx in obs and obs[reg_idx] == feat_idx_reg:\n",
        "                    pts_3d.append(point_cloud[pt_idx])\n",
        "                    pts_2d.append(keypoints_list[new_img_idx][feat_idx_new].pt)\n",
        "                    pt_indices.append((pt_idx, feat_idx_new))\n",
        "                    break\n",
        "    \n",
        "    return np.array(pts_3d), np.array(pts_2d), pt_indices\n",
        "\n",
        "# Register remaining images\n",
        "unregistered = [i for i in range(len(images)) if i not in registered]\n",
        "\n",
        "for new_idx in tqdm(unregistered, desc=\"Registering cameras\"):\n",
        "    # Find 2D-3D correspondences\n",
        "    pts_3d, pts_2d, pt_indices = find_2d3d_correspondences(new_idx, list(registered))\n",
        "    \n",
        "    if len(pts_3d) < MIN_MATCHES_PNP:\n",
        "        print(f\"âš ï¸  Image {new_idx}: insufficient 2D-3D matches ({len(pts_3d)})\")\n",
        "        continue\n",
        "    \n",
        "    # Solve PnP with RANSAC\n",
        "    success, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
        "        pts_3d, pts_2d, K, None,\n",
        "        reprojectionError=REPROJECTION_THRESHOLD,\n",
        "        confidence=0.99,\n",
        "        flags=cv2.SOLVEPNP_ITERATIVE\n",
        "    )\n",
        "    \n",
        "    if not success or inliers is None or len(inliers) < MIN_MATCHES_PNP:\n",
        "        print(f\"âš ï¸  Image {new_idx}: PnP failed\")\n",
        "        continue\n",
        "    \n",
        "    # Convert to rotation matrix\n",
        "    R_new, _ = cv2.Rodrigues(rvec)\n",
        "    t_new = tvec.reshape((3,1))\n",
        "    \n",
        "    # Store camera pose\n",
        "    camera_poses[new_idx] = (R_new, t_new)\n",
        "    registered.add(new_idx)\n",
        "    \n",
        "    # Update observations for inlier points\n",
        "    for inlier_idx in inliers.ravel():\n",
        "        pt_idx, feat_idx_new = pt_indices[inlier_idx]\n",
        "        point_observations[pt_idx][new_idx] = feat_idx_new\n",
        "    \n",
        "    print(f\"âœ… Image {new_idx}: registered with {len(inliers)} inliers\")\n",
        "\n",
        "print(f\"\\nâœ… Registered {len(registered)} / {len(images)} images\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 8: MAP EXPANSION - TRIANGULATE NEW POINTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 8: MAP EXPANSION - TRIANGULATE NEW POINTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 8: MAP EXPANSION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "initial_point_count = len(point_cloud)\n",
        "\n",
        "# For each pair of registered images, triangulate new points\n",
        "registered_list = sorted(list(registered))\n",
        "\n",
        "for i in tqdm(range(len(registered_list)), desc=\"Triangulating new points\"):\n",
        "    for j in range(i+1, len(registered_list)):\n",
        "        idx1 = registered_list[i]\n",
        "        idx2 = registered_list[j]\n",
        "        \n",
        "        # Match features\n",
        "        matches = match_features(idx1, idx2)\n",
        "        if len(matches) < MIN_MATCHES_TRIANGULATION:\n",
        "            continue\n",
        "        \n",
        "        # Get camera poses\n",
        "        R1, t1 = camera_poses[idx1]\n",
        "        R2, t2 = camera_poses[idx2]\n",
        "        P1 = K @ np.hstack((R1, t1))\n",
        "        P2 = K @ np.hstack((R2, t2))\n",
        "        \n",
        "        # Extract matched points\n",
        "        pts1_all = np.float32([keypoints_list[idx1][m.queryIdx].pt for m in matches])\n",
        "        pts2_all = np.float32([keypoints_list[idx2][m.trainIdx].pt for m in matches])\n",
        "        feat_idx1 = [m.queryIdx for m in matches]\n",
        "        feat_idx2 = [m.trainIdx for m in matches]\n",
        "        \n",
        "        # Check which matches are NOT already triangulated\n",
        "        new_matches_mask = []\n",
        "        for k, (m, f1, f2) in enumerate(zip(matches, feat_idx1, feat_idx2)):\n",
        "            already_exists = False\n",
        "            for pt_idx, obs in point_observations.items():\n",
        "                if idx1 in obs and obs[idx1] == f1:\n",
        "                    already_exists = True\n",
        "                    break\n",
        "            new_matches_mask.append(not already_exists)\n",
        "        \n",
        "        new_matches_mask = np.array(new_matches_mask)\n",
        "        if new_matches_mask.sum() < 4:\n",
        "            continue\n",
        "        \n",
        "        pts1_new = pts1_all[new_matches_mask]\n",
        "        pts2_new = pts2_all[new_matches_mask]\n",
        "        feat_idx1_new = [feat_idx1[k] for k in range(len(feat_idx1)) if new_matches_mask[k]]\n",
        "        feat_idx2_new = [feat_idx2[k] for k in range(len(feat_idx2)) if new_matches_mask[k]]\n",
        "        \n",
        "        # Triangulate\n",
        "        X4 = cv2.triangulatePoints(P1, P2, pts1_new.T, pts2_new.T)\n",
        "        new_points_3d = (X4[:3] / X4[3]).T\n",
        "        \n",
        "        # Cheirality check\n",
        "        mask1 = check_positive_depth(P1, new_points_3d)\n",
        "        mask2 = check_positive_depth(P2, new_points_3d)\n",
        "        valid = mask1 & mask2\n",
        "        \n",
        "        # Add valid points to map\n",
        "        for k in range(len(new_points_3d)):\n",
        "            if valid[k]:\n",
        "                pt_idx = len(point_cloud)\n",
        "                point_cloud.append(new_points_3d[k])\n",
        "                point_observations[pt_idx] = {\n",
        "                    idx1: feat_idx1_new[k],\n",
        "                    idx2: feat_idx2_new[k]\n",
        "                }\n",
        "\n",
        "new_points = len(point_cloud) - initial_point_count\n",
        "print(f\"âœ… Added {new_points} new 3D points\")\n",
        "print(f\"Total points in map: {len(point_cloud)}\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 9: BUNDLE ADJUSTMENT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 9: BUNDLE ADJUSTMENT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 9: BUNDLE ADJUSTMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def project_points(point_3d, R, t, K):\n",
        "    \"\"\"Project 3D point to 2D using camera parameters\"\"\"\n",
        "    point_cam = R @ point_3d + t.ravel()\n",
        "    point_2d_hom = K @ point_cam\n",
        "    return point_2d_hom[:2] / point_2d_hom[2]\n",
        "\n",
        "def residuals_ba(params, n_cameras, n_points, camera_indices, point_indices, points_2d, K):\n",
        "    \"\"\"\n",
        "    Compute residuals for bundle adjustment.\n",
        "    params: [camera_params (6*n_cameras), point_params (3*n_points)]\n",
        "    \"\"\"\n",
        "    camera_params = params[:n_cameras * 6].reshape((n_cameras, 6))\n",
        "    points_3d = params[n_cameras * 6:].reshape((n_points, 3))\n",
        "    \n",
        "    residuals = []\n",
        "    \n",
        "    for i in range(len(camera_indices)):\n",
        "        cam_idx = camera_indices[i]\n",
        "        pt_idx = point_indices[i]\n",
        "        observed_2d = points_2d[i]\n",
        "        \n",
        "        # Get camera parameters (rvec, tvec)\n",
        "        rvec = camera_params[cam_idx, :3]\n",
        "        tvec = camera_params[cam_idx, 3:].reshape(3, 1)\n",
        "        R, _ = cv2.Rodrigues(rvec)\n",
        "        \n",
        "        # Project point\n",
        "        projected = project_points(points_3d[pt_idx], R, tvec, K)\n",
        "        \n",
        "        # Compute residual\n",
        "        residuals.append(observed_2d[0] - projected[0])\n",
        "        residuals.append(observed_2d[1] - projected[1])\n",
        "    \n",
        "    return np.array(residuals)\n",
        "\n",
        "# Prepare data for bundle adjustment\n",
        "camera_indices = []\n",
        "point_indices = []\n",
        "points_2d_obs = []\n",
        "\n",
        "camera_id_map = {img_idx: i for i, img_idx in enumerate(sorted(registered))}\n",
        "point_id_map = {i: i for i in range(len(point_cloud))}\n",
        "\n",
        "for pt_idx, observations in point_observations.items():\n",
        "    for img_idx, feat_idx in observations.items():\n",
        "        if img_idx in camera_id_map:\n",
        "            camera_indices.append(camera_id_map[img_idx])\n",
        "            point_indices.append(point_id_map[pt_idx])\n",
        "            points_2d_obs.append(keypoints_list[img_idx][feat_idx].pt)\n",
        "\n",
        "camera_indices = np.array(camera_indices)\n",
        "point_indices = np.array(point_indices)\n",
        "points_2d_obs = np.array(points_2d_obs)\n",
        "\n",
        "print(f\"Bundle adjustment setup:\")\n",
        "print(f\"  Cameras: {len(camera_id_map)}\")\n",
        "print(f\"  Points: {len(point_cloud)}\")\n",
        "print(f\"  Observations: {len(camera_indices)}\")\n",
        "\n",
        "# Initialize parameters\n",
        "n_cameras = len(camera_id_map)\n",
        "n_points = len(point_cloud)\n",
        "\n",
        "camera_params_init = np.zeros((n_cameras, 6))\n",
        "for img_idx, cam_id in camera_id_map.items():\n",
        "    R, t = camera_poses[img_idx]\n",
        "    rvec, _ = cv2.Rodrigues(R)\n",
        "    camera_params_init[cam_id, :3] = rvec.ravel()\n",
        "    camera_params_init[cam_id, 3:] = t.ravel()\n",
        "\n",
        "points_3d_init = np.array(point_cloud)\n",
        "\n",
        "# Concatenate all parameters\n",
        "x0 = np.hstack([camera_params_init.ravel(), points_3d_init.ravel()])\n",
        "\n",
        "print(f\"\\nRunning bundle adjustment optimization...\")\n",
        "print(f\"Initial parameters: {len(x0)}\")\n",
        "\n",
        "# Run optimization\n",
        "result = least_squares(\n",
        "    residuals_ba,\n",
        "    x0,\n",
        "    args=(n_cameras, n_points, camera_indices, point_indices, points_2d_obs, K),\n",
        "    verbose=2,\n",
        "    max_nfev=100,  # Limit iterations for Colab\n",
        "    ftol=1e-4,\n",
        "    method='trf'\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Bundle adjustment complete!\")\n",
        "print(f\"  Initial cost: {result.fun.sum():.2f}\")\n",
        "print(f\"  Final cost: {np.sum(result.fun**2):.2f}\")\n",
        "print(f\"  Iterations: {result.nfev}\")\n",
        "\n",
        "# Extract optimized parameters\n",
        "camera_params_opt = result.x[:n_cameras * 6].reshape((n_cameras, 6))\n",
        "points_3d_opt = result.x[n_cameras * 6:].reshape((n_points, 3))\n",
        "\n",
        "# Update camera poses\n",
        "for img_idx, cam_id in camera_id_map.items():\n",
        "    rvec_opt = camera_params_opt[cam_id, :3]\n",
        "    tvec_opt = camera_params_opt[cam_id, 3:]\n",
        "    R_opt, _ = cv2.Rodrigues(rvec_opt)\n",
        "    camera_poses[img_idx] = (R_opt, tvec_opt.reshape(3, 1))\n",
        "\n",
        "# Update point cloud\n",
        "point_cloud_refined = points_3d_opt\n",
        "\n",
        "print(f\"\\nâœ… Point cloud refined: {len(point_cloud_refined)} points\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 10: OUTLIER REMOVAL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 10: OUTLIER REMOVAL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 10: OUTLIER REMOVAL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Remove statistical outliers\n",
        "z_scores = np.abs(stats.zscore(point_cloud_refined, axis=0))\n",
        "outlier_mask = (z_scores < 3).all(axis=1)\n",
        "points_clean = point_cloud_refined[outlier_mask]\n",
        "\n",
        "print(f\"Points before outlier removal: {len(point_cloud_refined)}\")\n",
        "print(f\"Points after outlier removal: {len(points_clean)}\")\n",
        "print(f\"Removed {len(point_cloud_refined) - len(points_clean)} outliers\")\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 11: VISUALIZATION\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 11: VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STEP 11: 3D VISUALIZATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create Open3D point cloud\n",
        "pcd = o3d.geometry.PointCloud()\n",
        "pcd.points = o3d.utility.Vector3dVector(points_clean)\n",
        "pcd.paint_uniform_color([0.2, 0.6, 1.0])\n",
        "pcd.estimate_normals()\n",
        "\n",
        "# Save to file\n",
        "output_ply = \"/content/week3_refined_sparse.ply\"\n",
        "o3d.io.write_point_cloud(output_ply, pcd)\n",
        "print(f\"âœ… Saved refined point cloud: {output_ply}\")\n",
        "\n",
        "# Plotly visualization\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=points_clean[:,0],\n",
        "    y=points_clean[:,1],\n",
        "    z=points_clean[:,2],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=2,\n",
        "        color=points_clean[:,2],\n",
        "        colorscale='Viridis',\n",
        "        opacity=0.8,\n",
        "        colorbar=dict(title=\"Depth (Z)\")\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Week 3: Refined Sparse Point Cloud (After Bundle Adjustment)\",\n",
        "    scene=dict(\n",
        "        xaxis_title='X',\n",
        "        yaxis_title='Y',\n",
        "        zaxis_title='Z',\n",
        "        aspectmode='data'\n",
        "    ),\n",
        "    width=900,\n",
        "    height=700\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 12: FINAL SUMMARY\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 12: FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WEEK 3 DELIVERABLE SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nâœ… Input: {len(images)} images\")\n",
        "print(f\"âœ… Registered cameras: {len(registered)} / {len(images)}\")\n",
        "print(f\"âœ… Initial 3D points: {initial_point_count}\")\n",
        "print(f\"âœ… After map expansion: {len(point_cloud)}\")\n",
        "print(f\"âœ… After bundle adjustment & cleaning: {len(points_clean)}\")\n",
        "print(f\"âœ… Total observations: {len(camera_indices)}\")\n",
        "print(f\"\\nâœ… Output saved to: {output_ply}\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
